{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"./data/house/all_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 1460\n",
    "\n",
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"./data/house/train.csv\")['SalePrice']\n",
    "y_train = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "# import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_x = StandardScaler()\n",
    "std_x.fit(train.values)\n",
    "x_scaled = std_x.transform(train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the 'Id' column\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = np.exp(lr.predict(std_x.transform(test.values)))\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "?optimizers.Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 223)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 512)               114688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 149,889\n",
      "Trainable params: 148,737\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "input_x = Input(shape=(x_scaled.shape[1],))\n",
    "\n",
    "\n",
    "h1 = Dense(512,activation='relu',\n",
    "               kernel_regularizer=regularizers.l1(0.005),)(input_x)\n",
    "n1 = BatchNormalization()(h1)\n",
    "\n",
    "\n",
    "h2 = Dense(64,activation='relu',\n",
    "               kernel_regularizer=regularizers.l1(0.005),)(n1)\n",
    "n2 = BatchNormalization()(h2)\n",
    "\n",
    "\n",
    "output = Dense(1,activation='linear',\n",
    "               kernel_regularizer=regularizers.l1(0.005),)(n2)\n",
    "\n",
    "model = Model(input_x,output)\n",
    "model.compile(optimizer=optimizers.Adagrad(lr=0.05),\n",
    "              loss='mean_squared_error',)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1314 samples, validate on 146 samples\n",
      "Epoch 1/2000\n",
      "1314/1314 [==============================] - 1s 993us/step - loss: 32.4300 - val_loss: 17.4491\n",
      "Epoch 2/2000\n",
      "1314/1314 [==============================] - 0s 333us/step - loss: 13.0284 - val_loss: 13.6218\n",
      "Epoch 3/2000\n",
      "1314/1314 [==============================] - 0s 319us/step - loss: 9.9133 - val_loss: 18.9464\n",
      "Epoch 4/2000\n",
      "1314/1314 [==============================] - 0s 324us/step - loss: 10.4011 - val_loss: 6.8345\n",
      "Epoch 5/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 7.2203 - val_loss: 8.9166\n",
      "Epoch 6/2000\n",
      "1314/1314 [==============================] - 0s 330us/step - loss: 7.2801 - val_loss: 6.2197\n",
      "Epoch 7/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 5.7912 - val_loss: 5.0510\n",
      "Epoch 8/2000\n",
      "1314/1314 [==============================] - 0s 339us/step - loss: 4.2467 - val_loss: 4.1541\n",
      "Epoch 9/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 5.7811 - val_loss: 5.3902\n",
      "Epoch 10/2000\n",
      "1314/1314 [==============================] - 0s 337us/step - loss: 4.8665 - val_loss: 4.6899\n",
      "Epoch 11/2000\n",
      "1314/1314 [==============================] - 0s 363us/step - loss: 3.6535 - val_loss: 2.8892\n",
      "Epoch 12/2000\n",
      "1314/1314 [==============================] - 0s 346us/step - loss: 2.8154 - val_loss: 2.4665\n",
      "Epoch 13/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 2.9912 - val_loss: 2.3092\n",
      "Epoch 14/2000\n",
      "1314/1314 [==============================] - 0s 334us/step - loss: 2.7289 - val_loss: 11.3387\n",
      "Epoch 15/2000\n",
      "1314/1314 [==============================] - 0s 332us/step - loss: 3.4257 - val_loss: 3.1676\n",
      "Epoch 16/2000\n",
      "1314/1314 [==============================] - 0s 362us/step - loss: 2.6160 - val_loss: 5.6221\n",
      "Epoch 17/2000\n",
      "1314/1314 [==============================] - 0s 346us/step - loss: 2.8652 - val_loss: 8.1070\n",
      "Epoch 18/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 3.7131 - val_loss: 3.3830\n",
      "Epoch 19/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 3.1070 - val_loss: 2.7045\n",
      "Epoch 20/2000\n",
      "1314/1314 [==============================] - 0s 357us/step - loss: 2.3091 - val_loss: 2.6180\n",
      "Epoch 21/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 2.0647 - val_loss: 2.7870\n",
      "Epoch 22/2000\n",
      "1314/1314 [==============================] - 0s 360us/step - loss: 2.1523 - val_loss: 1.8249\n",
      "Epoch 23/2000\n",
      "1314/1314 [==============================] - 0s 356us/step - loss: 1.7777 - val_loss: 2.3545\n",
      "Epoch 24/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 1.9927 - val_loss: 1.7876\n",
      "Epoch 25/2000\n",
      "1314/1314 [==============================] - 0s 354us/step - loss: 1.4718 - val_loss: 1.3606\n",
      "Epoch 26/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 1.2588 - val_loss: 1.2332\n",
      "Epoch 27/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 1.6063 - val_loss: 1.4584\n",
      "Epoch 28/2000\n",
      "1314/1314 [==============================] - 0s 338us/step - loss: 1.2779 - val_loss: 1.8093\n",
      "Epoch 29/2000\n",
      "1314/1314 [==============================] - 0s 357us/step - loss: 1.5009 - val_loss: 8.6643\n",
      "Epoch 30/2000\n",
      "1314/1314 [==============================] - 0s 336us/step - loss: 1.8642 - val_loss: 1.4711\n",
      "Epoch 31/2000\n",
      "1314/1314 [==============================] - 0s 349us/step - loss: 1.3282 - val_loss: 1.2204\n",
      "Epoch 32/2000\n",
      "1314/1314 [==============================] - 0s 358us/step - loss: 1.2434 - val_loss: 2.7697\n",
      "Epoch 33/2000\n",
      "1314/1314 [==============================] - 0s 366us/step - loss: 1.2835 - val_loss: 1.3014\n",
      "Epoch 34/2000\n",
      "1314/1314 [==============================] - 0s 356us/step - loss: 1.1912 - val_loss: 1.3494\n",
      "Epoch 35/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.9687 - val_loss: 1.1498\n",
      "Epoch 36/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.9105 - val_loss: 1.4264\n",
      "Epoch 37/2000\n",
      "1314/1314 [==============================] - 0s 353us/step - loss: 1.0824 - val_loss: 3.9530\n",
      "Epoch 38/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 1.0935 - val_loss: 1.6330\n",
      "Epoch 39/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 1.2754 - val_loss: 1.0003\n",
      "Epoch 40/2000\n",
      "1314/1314 [==============================] - 0s 354us/step - loss: 0.8937 - val_loss: 0.8897\n",
      "Epoch 41/2000\n",
      "1314/1314 [==============================] - 0s 339us/step - loss: 0.7838 - val_loss: 0.6941\n",
      "Epoch 42/2000\n",
      "1314/1314 [==============================] - 0s 348us/step - loss: 0.7237 - val_loss: 0.6966\n",
      "Epoch 43/2000\n",
      "1314/1314 [==============================] - 0s 353us/step - loss: 0.6816 - val_loss: 0.9492\n",
      "Epoch 44/2000\n",
      "1314/1314 [==============================] - 0s 360us/step - loss: 0.8654 - val_loss: 0.7057\n",
      "Epoch 45/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.6477 - val_loss: 0.5643\n",
      "Epoch 46/2000\n",
      "1314/1314 [==============================] - 1s 388us/step - loss: 0.5868 - val_loss: 0.6571\n",
      "Epoch 47/2000\n",
      "1314/1314 [==============================] - 0s 349us/step - loss: 1.1136 - val_loss: 0.8257\n",
      "Epoch 48/2000\n",
      "1314/1314 [==============================] - 0s 328us/step - loss: 0.7404 - val_loss: 0.6697\n",
      "Epoch 49/2000\n",
      "1314/1314 [==============================] - 0s 354us/step - loss: 0.6867 - val_loss: 0.7587\n",
      "Epoch 50/2000\n",
      "1314/1314 [==============================] - 0s 337us/step - loss: 0.6843 - val_loss: 0.7831\n",
      "Epoch 51/2000\n",
      "1314/1314 [==============================] - 0s 342us/step - loss: 0.6084 - val_loss: 0.5695\n",
      "Epoch 52/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.6586 - val_loss: 0.8932\n",
      "Epoch 53/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 1.0212 - val_loss: 0.9276\n",
      "Epoch 54/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.6942 - val_loss: 0.6292\n",
      "Epoch 55/2000\n",
      "1314/1314 [==============================] - 0s 333us/step - loss: 0.5702 - val_loss: 0.5799\n",
      "Epoch 56/2000\n",
      "1314/1314 [==============================] - 0s 357us/step - loss: 0.5403 - val_loss: 0.5093\n",
      "Epoch 57/2000\n",
      "1314/1314 [==============================] - 0s 348us/step - loss: 0.5094 - val_loss: 0.4547\n",
      "Epoch 58/2000\n",
      "1314/1314 [==============================] - 0s 372us/step - loss: 0.4877 - val_loss: 1.7154\n",
      "Epoch 59/2000\n",
      "1314/1314 [==============================] - 0s 350us/step - loss: 0.6415 - val_loss: 0.5291\n",
      "Epoch 60/2000\n",
      "1314/1314 [==============================] - 0s 346us/step - loss: 0.5050 - val_loss: 0.5701\n",
      "Epoch 61/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.4768 - val_loss: 1.5684\n",
      "Epoch 62/2000\n",
      "1314/1314 [==============================] - 0s 336us/step - loss: 0.5213 - val_loss: 4.1674\n",
      "Epoch 63/2000\n",
      "1314/1314 [==============================] - 0s 365us/step - loss: 0.7966 - val_loss: 0.9303\n",
      "Epoch 64/2000\n",
      "1314/1314 [==============================] - 0s 364us/step - loss: 0.7111 - val_loss: 0.5852\n",
      "Epoch 65/2000\n",
      "1314/1314 [==============================] - 0s 326us/step - loss: 0.5519 - val_loss: 0.7227\n",
      "Epoch 66/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.7077 - val_loss: 0.6034\n",
      "Epoch 67/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.5322 - val_loss: 0.6709\n",
      "Epoch 68/2000\n",
      "1314/1314 [==============================] - 0s 353us/step - loss: 0.5932 - val_loss: 0.5291\n",
      "Epoch 69/2000\n",
      "1314/1314 [==============================] - 0s 338us/step - loss: 0.4994 - val_loss: 0.5300\n",
      "Epoch 70/2000\n",
      "1314/1314 [==============================] - 0s 354us/step - loss: 0.4794 - val_loss: 0.4679\n",
      "Epoch 71/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 0.4404 - val_loss: 1.1511\n",
      "Epoch 72/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.7587 - val_loss: 0.7928\n",
      "Epoch 73/2000\n",
      "1314/1314 [==============================] - 0s 374us/step - loss: 0.6136 - val_loss: 0.4924\n",
      "Epoch 74/2000\n",
      "1314/1314 [==============================] - 0s 376us/step - loss: 0.4781 - val_loss: 0.4658\n",
      "Epoch 75/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 0.4348 - val_loss: 0.4214\n",
      "Epoch 76/2000\n",
      "1314/1314 [==============================] - 0s 352us/step - loss: 0.4560 - val_loss: 0.4278\n",
      "Epoch 77/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 0s 321us/step - loss: 0.4229 - val_loss: 0.8785\n",
      "Epoch 78/2000\n",
      "1314/1314 [==============================] - 0s 322us/step - loss: 0.4797 - val_loss: 0.4054\n",
      "Epoch 79/2000\n",
      "1314/1314 [==============================] - 0s 322us/step - loss: 0.4157 - val_loss: 0.4108\n",
      "Epoch 80/2000\n",
      "1314/1314 [==============================] - 0s 323us/step - loss: 0.4030 - val_loss: 0.5108\n",
      "Epoch 81/2000\n",
      "1314/1314 [==============================] - 0s 321us/step - loss: 0.4618 - val_loss: 0.5807\n",
      "Epoch 82/2000\n",
      "1314/1314 [==============================] - 0s 325us/step - loss: 0.4319 - val_loss: 1.1707\n",
      "Epoch 83/2000\n",
      "1314/1314 [==============================] - 0s 338us/step - loss: 0.5113 - val_loss: 1.1108\n",
      "Epoch 84/2000\n",
      "1314/1314 [==============================] - 0s 336us/step - loss: 0.5403 - val_loss: 0.7315\n",
      "Epoch 85/2000\n",
      "1314/1314 [==============================] - 0s 324us/step - loss: 0.5024 - val_loss: 0.4779\n",
      "Epoch 86/2000\n",
      "1314/1314 [==============================] - 0s 334us/step - loss: 0.3996 - val_loss: 0.3755\n",
      "Epoch 87/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.3695 - val_loss: 0.3508\n",
      "Epoch 88/2000\n",
      "1314/1314 [==============================] - 0s 333us/step - loss: 0.3496 - val_loss: 0.3298\n",
      "Epoch 89/2000\n",
      "1314/1314 [==============================] - 0s 350us/step - loss: 0.3520 - val_loss: 0.5574\n",
      "Epoch 90/2000\n",
      "1314/1314 [==============================] - 0s 343us/step - loss: 0.5007 - val_loss: 0.6984\n",
      "Epoch 91/2000\n",
      "1314/1314 [==============================] - 0s 346us/step - loss: 0.4538 - val_loss: 0.8878\n",
      "Epoch 92/2000\n",
      "1314/1314 [==============================] - 0s 342us/step - loss: 0.4779 - val_loss: 0.4578\n",
      "Epoch 93/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.4272 - val_loss: 0.3957\n",
      "Epoch 94/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.3841 - val_loss: 0.3639\n",
      "Epoch 95/2000\n",
      "1314/1314 [==============================] - 0s 348us/step - loss: 0.3536 - val_loss: 0.3285\n",
      "Epoch 96/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 0.3384 - val_loss: 0.3172\n",
      "Epoch 97/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.3390 - val_loss: 0.3095\n",
      "Epoch 98/2000\n",
      "1314/1314 [==============================] - 0s 328us/step - loss: 0.3221 - val_loss: 0.3366\n",
      "Epoch 99/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.3270 - val_loss: 0.3328\n",
      "Epoch 100/2000\n",
      "1314/1314 [==============================] - 0s 337us/step - loss: 0.3309 - val_loss: 0.3222\n",
      "Epoch 101/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 0.3339 - val_loss: 0.6568\n",
      "Epoch 102/2000\n",
      "1314/1314 [==============================] - 0s 327us/step - loss: 0.3525 - val_loss: 0.3211\n",
      "Epoch 103/2000\n",
      "1314/1314 [==============================] - 0s 323us/step - loss: 0.3222 - val_loss: 0.3121\n",
      "Epoch 104/2000\n",
      "1314/1314 [==============================] - 0s 324us/step - loss: 0.3239 - val_loss: 0.3218\n",
      "Epoch 105/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.3168 - val_loss: 0.3016\n",
      "Epoch 106/2000\n",
      "1314/1314 [==============================] - 0s 334us/step - loss: 0.3109 - val_loss: 0.2898\n",
      "Epoch 107/2000\n",
      "1314/1314 [==============================] - 0s 336us/step - loss: 0.3258 - val_loss: 0.2931\n",
      "Epoch 108/2000\n",
      "1314/1314 [==============================] - 0s 328us/step - loss: 0.3204 - val_loss: 0.2996\n",
      "Epoch 109/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 0.3225 - val_loss: 8.2548\n",
      "Epoch 110/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.6211 - val_loss: 0.5322\n",
      "Epoch 111/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 0.4480 - val_loss: 0.7249\n",
      "Epoch 112/2000\n",
      "1314/1314 [==============================] - 0s 334us/step - loss: 0.3972 - val_loss: 0.3688\n",
      "Epoch 113/2000\n",
      "1314/1314 [==============================] - 0s 346us/step - loss: 0.3428 - val_loss: 0.3890\n",
      "Epoch 114/2000\n",
      "1314/1314 [==============================] - 0s 334us/step - loss: 0.3394 - val_loss: 0.3043\n",
      "Epoch 115/2000\n",
      "1314/1314 [==============================] - 0s 328us/step - loss: 0.3103 - val_loss: 0.4905\n",
      "Epoch 116/2000\n",
      "1314/1314 [==============================] - 0s 342us/step - loss: 0.3047 - val_loss: 0.2849\n",
      "Epoch 117/2000\n",
      "1314/1314 [==============================] - 0s 354us/step - loss: 0.2921 - val_loss: 0.2742\n",
      "Epoch 118/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.2918 - val_loss: 0.2782\n",
      "Epoch 119/2000\n",
      "1314/1314 [==============================] - 0s 337us/step - loss: 0.2809 - val_loss: 0.2617\n",
      "Epoch 120/2000\n",
      "1314/1314 [==============================] - 0s 352us/step - loss: 0.2785 - val_loss: 0.2673\n",
      "Epoch 121/2000\n",
      "1314/1314 [==============================] - 0s 326us/step - loss: 0.2743 - val_loss: 0.4591\n",
      "Epoch 122/2000\n",
      "1314/1314 [==============================] - 0s 332us/step - loss: 0.2807 - val_loss: 0.2715\n",
      "Epoch 123/2000\n",
      "1314/1314 [==============================] - 0s 322us/step - loss: 0.2783 - val_loss: 0.3215\n",
      "Epoch 124/2000\n",
      "1314/1314 [==============================] - 0s 342us/step - loss: 0.2830 - val_loss: 0.3133\n",
      "Epoch 125/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.2866 - val_loss: 0.2487\n",
      "Epoch 126/2000\n",
      "1314/1314 [==============================] - 0s 359us/step - loss: 0.2698 - val_loss: 0.2510\n",
      "Epoch 127/2000\n",
      "1314/1314 [==============================] - 0s 342us/step - loss: 0.2746 - val_loss: 0.4207\n",
      "Epoch 128/2000\n",
      "1314/1314 [==============================] - 0s 353us/step - loss: 0.2748 - val_loss: 0.3411\n",
      "Epoch 129/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 0.2813 - val_loss: 0.3046\n",
      "Epoch 130/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.2745 - val_loss: 0.7471\n",
      "Epoch 131/2000\n",
      "1314/1314 [==============================] - 0s 359us/step - loss: 0.4344 - val_loss: 0.3499\n",
      "Epoch 132/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 0.3160 - val_loss: 0.4787\n",
      "Epoch 133/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.3079 - val_loss: 0.2659\n",
      "Epoch 134/2000\n",
      "1314/1314 [==============================] - 0s 338us/step - loss: 0.2787 - val_loss: 0.2617\n",
      "Epoch 135/2000\n",
      "1314/1314 [==============================] - 0s 358us/step - loss: 0.2660 - val_loss: 0.7791\n",
      "Epoch 136/2000\n",
      "1314/1314 [==============================] - 1s 403us/step - loss: 0.2840 - val_loss: 0.2583\n",
      "Epoch 137/2000\n",
      "1314/1314 [==============================] - 1s 491us/step - loss: 0.2606 - val_loss: 0.2349\n",
      "Epoch 138/2000\n",
      "1314/1314 [==============================] - 1s 408us/step - loss: 0.2531 - val_loss: 0.4285\n",
      "Epoch 139/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 0.3117 - val_loss: 0.2688\n",
      "Epoch 140/2000\n",
      "1314/1314 [==============================] - 0s 339us/step - loss: 0.2628 - val_loss: 0.2899\n",
      "Epoch 141/2000\n",
      "1314/1314 [==============================] - 1s 391us/step - loss: 0.2551 - val_loss: 0.2644\n",
      "Epoch 142/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 0.2574 - val_loss: 0.7991\n",
      "Epoch 143/2000\n",
      "1314/1314 [==============================] - 0s 350us/step - loss: 0.3890 - val_loss: 0.3298\n",
      "Epoch 144/2000\n",
      "1314/1314 [==============================] - 0s 370us/step - loss: 0.2890 - val_loss: 0.2687\n",
      "Epoch 145/2000\n",
      "1314/1314 [==============================] - 0s 352us/step - loss: 0.2678 - val_loss: 0.2649\n",
      "Epoch 146/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.2604 - val_loss: 0.2573\n",
      "Epoch 147/2000\n",
      "1314/1314 [==============================] - 0s 343us/step - loss: 0.2548 - val_loss: 0.2537\n",
      "Epoch 148/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.2480 - val_loss: 0.2327\n",
      "Epoch 149/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.2461 - val_loss: 0.2652\n",
      "Epoch 150/2000\n",
      "1314/1314 [==============================] - 0s 348us/step - loss: 0.2530 - val_loss: 0.2268\n",
      "Epoch 151/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.2434 - val_loss: 0.2364\n",
      "Epoch 152/2000\n",
      "1314/1314 [==============================] - 0s 361us/step - loss: 0.2432 - val_loss: 0.3141\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.2460 - val_loss: 0.3190\n",
      "Epoch 154/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.2549 - val_loss: 0.2381\n",
      "Epoch 155/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.2443 - val_loss: 0.2295\n",
      "Epoch 156/2000\n",
      "1314/1314 [==============================] - 0s 311us/step - loss: 0.2435 - val_loss: 0.2777\n",
      "Epoch 157/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.2422 - val_loss: 0.2464\n",
      "Epoch 158/2000\n",
      "1314/1314 [==============================] - 0s 320us/step - loss: 0.2423 - val_loss: 0.2621\n",
      "Epoch 159/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.2368 - val_loss: 0.2262\n",
      "Epoch 160/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.2427 - val_loss: 0.2417\n",
      "Epoch 161/2000\n",
      "1314/1314 [==============================] - 0s 314us/step - loss: 0.2404 - val_loss: 0.2450\n",
      "Epoch 162/2000\n",
      "1314/1314 [==============================] - 0s 319us/step - loss: 0.2354 - val_loss: 0.2613\n",
      "Epoch 163/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.2410 - val_loss: 0.2254\n",
      "Epoch 164/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.2359 - val_loss: 0.2174\n",
      "Epoch 165/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.2377 - val_loss: 0.2398\n",
      "Epoch 166/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.2293 - val_loss: 0.2321\n",
      "Epoch 167/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.2322 - val_loss: 0.2906\n",
      "Epoch 168/2000\n",
      "1314/1314 [==============================] - 0s 318us/step - loss: 0.2534 - val_loss: 0.3042\n",
      "Epoch 169/2000\n",
      "1314/1314 [==============================] - 0s 326us/step - loss: 0.2606 - val_loss: 0.2661\n",
      "Epoch 170/2000\n",
      "1314/1314 [==============================] - 0s 364us/step - loss: 0.2453 - val_loss: 0.2307\n",
      "Epoch 171/2000\n",
      "1314/1314 [==============================] - 0s 350us/step - loss: 0.2321 - val_loss: 0.3097\n",
      "Epoch 172/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 0.2423 - val_loss: 0.2295\n",
      "Epoch 173/2000\n",
      "1314/1314 [==============================] - 0s 337us/step - loss: 0.2284 - val_loss: 0.2804\n",
      "Epoch 174/2000\n",
      "1314/1314 [==============================] - 0s 363us/step - loss: 0.2365 - val_loss: 0.3010\n",
      "Epoch 175/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 0.2423 - val_loss: 0.2220\n",
      "Epoch 176/2000\n",
      "1314/1314 [==============================] - 0s 321us/step - loss: 0.2368 - val_loss: 0.2168\n",
      "Epoch 177/2000\n",
      "1314/1314 [==============================] - 0s 311us/step - loss: 0.2321 - val_loss: 0.2150\n",
      "Epoch 178/2000\n",
      "1314/1314 [==============================] - 0s 333us/step - loss: 0.2222 - val_loss: 0.2278\n",
      "Epoch 179/2000\n",
      "1314/1314 [==============================] - 0s 361us/step - loss: 0.2237 - val_loss: 0.2500\n",
      "Epoch 180/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 0.2225 - val_loss: 0.2463\n",
      "Epoch 181/2000\n",
      "1314/1314 [==============================] - 0s 338us/step - loss: 0.2331 - val_loss: 0.2596\n",
      "Epoch 182/2000\n",
      "1314/1314 [==============================] - 0s 360us/step - loss: 0.2273 - val_loss: 0.2117\n",
      "Epoch 183/2000\n",
      "1314/1314 [==============================] - 0s 366us/step - loss: 0.2235 - val_loss: 0.2375\n",
      "Epoch 184/2000\n",
      "1314/1314 [==============================] - 1s 593us/step - loss: 0.2232 - val_loss: 0.2062\n",
      "Epoch 185/2000\n",
      "1314/1314 [==============================] - 0s 333us/step - loss: 0.2201 - val_loss: 0.2094\n",
      "Epoch 186/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.2165 - val_loss: 0.2242\n",
      "Epoch 187/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.2208 - val_loss: 0.2092\n",
      "Epoch 188/2000\n",
      "1314/1314 [==============================] - 0s 314us/step - loss: 0.2201 - val_loss: 0.2263\n",
      "Epoch 189/2000\n",
      "1314/1314 [==============================] - 0s 348us/step - loss: 0.2187 - val_loss: 0.2510\n",
      "Epoch 190/2000\n",
      "1314/1314 [==============================] - 1s 381us/step - loss: 0.2213 - val_loss: 0.2032\n",
      "Epoch 191/2000\n",
      "1314/1314 [==============================] - 0s 314us/step - loss: 0.2085 - val_loss: 0.1942\n",
      "Epoch 192/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.2181 - val_loss: 0.4571\n",
      "Epoch 193/2000\n",
      "1314/1314 [==============================] - 0s 327us/step - loss: 0.2233 - val_loss: 0.2702\n",
      "Epoch 194/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.2145 - val_loss: 0.3483\n",
      "Epoch 195/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.2205 - val_loss: 0.1984\n",
      "Epoch 196/2000\n",
      "1314/1314 [==============================] - 0s 311us/step - loss: 0.2092 - val_loss: 0.2423\n",
      "Epoch 197/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.2137 - val_loss: 0.2649\n",
      "Epoch 198/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.2241 - val_loss: 0.2117\n",
      "Epoch 199/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.2169 - val_loss: 0.2021\n",
      "Epoch 200/2000\n",
      "1314/1314 [==============================] - 0s 322us/step - loss: 0.2177 - val_loss: 0.2024\n",
      "Epoch 201/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.2123 - val_loss: 0.2182\n",
      "Epoch 202/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.2105 - val_loss: 0.1929\n",
      "Epoch 203/2000\n",
      "1314/1314 [==============================] - 0s 352us/step - loss: 0.2113 - val_loss: 0.2020\n",
      "Epoch 204/2000\n",
      "1314/1314 [==============================] - 0s 322us/step - loss: 0.2120 - val_loss: 0.2016\n",
      "Epoch 205/2000\n",
      "1314/1314 [==============================] - 0s 322us/step - loss: 0.2200 - val_loss: 0.1938\n",
      "Epoch 206/2000\n",
      "1314/1314 [==============================] - 0s 362us/step - loss: 0.2096 - val_loss: 0.1941\n",
      "Epoch 207/2000\n",
      "1314/1314 [==============================] - 0s 364us/step - loss: 0.2096 - val_loss: 0.2051\n",
      "Epoch 208/2000\n",
      "1314/1314 [==============================] - 0s 320us/step - loss: 0.2088 - val_loss: 0.2349\n",
      "Epoch 209/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.2126 - val_loss: 0.2704\n",
      "Epoch 210/2000\n",
      "1314/1314 [==============================] - 0s 311us/step - loss: 0.2089 - val_loss: 0.2939\n",
      "Epoch 211/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.2123 - val_loss: 0.1930\n",
      "Epoch 212/2000\n",
      "1314/1314 [==============================] - 0s 314us/step - loss: 0.2023 - val_loss: 0.7272\n",
      "Epoch 213/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.5788 - val_loss: 0.4223\n",
      "Epoch 214/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.3709 - val_loss: 0.2847\n",
      "Epoch 215/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.2709 - val_loss: 0.2573\n",
      "Epoch 216/2000\n",
      "1314/1314 [==============================] - 1s 403us/step - loss: 0.2416 - val_loss: 0.2218\n",
      "Epoch 217/2000\n",
      "1314/1314 [==============================] - 1s 391us/step - loss: 0.2280 - val_loss: 0.2073\n",
      "Epoch 218/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.2144 - val_loss: 0.2048\n",
      "Epoch 219/2000\n",
      "1314/1314 [==============================] - 0s 321us/step - loss: 0.2097 - val_loss: 0.1950\n",
      "Epoch 220/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.2027 - val_loss: 0.1849\n",
      "Epoch 221/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.2036 - val_loss: 0.2928\n",
      "Epoch 222/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.2136 - val_loss: 0.2033\n",
      "Epoch 223/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.2066 - val_loss: 0.1993\n",
      "Epoch 224/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 0.1999 - val_loss: 0.2023\n",
      "Epoch 225/2000\n",
      "1314/1314 [==============================] - 0s 367us/step - loss: 0.2010 - val_loss: 0.2791\n",
      "Epoch 226/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.2027 - val_loss: 0.2056\n",
      "Epoch 227/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1973 - val_loss: 0.1798\n",
      "Epoch 228/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.1954 - val_loss: 0.1973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/2000\n",
      "1314/1314 [==============================] - 0s 375us/step - loss: 0.1965 - val_loss: 0.1775\n",
      "Epoch 230/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.1961 - val_loss: 0.1866\n",
      "Epoch 231/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1951 - val_loss: 0.1786\n",
      "Epoch 232/2000\n",
      "1314/1314 [==============================] - 0s 379us/step - loss: 0.1935 - val_loss: 0.2216\n",
      "Epoch 233/2000\n",
      "1314/1314 [==============================] - 1s 385us/step - loss: 0.1956 - val_loss: 0.2704\n",
      "Epoch 234/2000\n",
      "1314/1314 [==============================] - 0s 333us/step - loss: 0.2086 - val_loss: 0.2070\n",
      "Epoch 235/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1973 - val_loss: 0.2302\n",
      "Epoch 236/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1930 - val_loss: 0.1970\n",
      "Epoch 237/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1999 - val_loss: 0.1868\n",
      "Epoch 238/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1932 - val_loss: 0.1708\n",
      "Epoch 239/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1887 - val_loss: 0.1697\n",
      "Epoch 240/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1864 - val_loss: 0.2240\n",
      "Epoch 241/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1983 - val_loss: 0.1816\n",
      "Epoch 242/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.1901 - val_loss: 0.1779\n",
      "Epoch 243/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1898 - val_loss: 0.3130\n",
      "Epoch 244/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1913 - val_loss: 0.2207\n",
      "Epoch 245/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.1856 - val_loss: 0.1864\n",
      "Epoch 246/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1863 - val_loss: 0.2504\n",
      "Epoch 247/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1910 - val_loss: 0.1985\n",
      "Epoch 248/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1852 - val_loss: 0.1898\n",
      "Epoch 249/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1904 - val_loss: 0.1958\n",
      "Epoch 250/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1854 - val_loss: 0.1762\n",
      "Epoch 251/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1904 - val_loss: 0.1852\n",
      "Epoch 252/2000\n",
      "1314/1314 [==============================] - 0s 311us/step - loss: 0.1886 - val_loss: 0.1668\n",
      "Epoch 253/2000\n",
      "1314/1314 [==============================] - 0s 314us/step - loss: 0.1874 - val_loss: 0.1924\n",
      "Epoch 254/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1911 - val_loss: 0.2271\n",
      "Epoch 255/2000\n",
      "1314/1314 [==============================] - 0s 323us/step - loss: 0.1920 - val_loss: 0.1817\n",
      "Epoch 256/2000\n",
      "1314/1314 [==============================] - 1s 409us/step - loss: 0.1861 - val_loss: 0.2492\n",
      "Epoch 257/2000\n",
      "1314/1314 [==============================] - 0s 325us/step - loss: 0.1974 - val_loss: 0.2310\n",
      "Epoch 258/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.2564 - val_loss: 0.1937\n",
      "Epoch 259/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.2083 - val_loss: 0.2295\n",
      "Epoch 260/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.2107 - val_loss: 0.1768\n",
      "Epoch 261/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1909 - val_loss: 0.2929\n",
      "Epoch 262/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.1939 - val_loss: 0.1861\n",
      "Epoch 263/2000\n",
      "1314/1314 [==============================] - ETA: 0s - loss: 0.192 - 0s 310us/step - loss: 0.1912 - val_loss: 0.1688\n",
      "Epoch 264/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1919 - val_loss: 0.1789\n",
      "Epoch 265/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1834 - val_loss: 0.1762\n",
      "Epoch 266/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1796 - val_loss: 0.2019\n",
      "Epoch 267/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1852 - val_loss: 0.1712\n",
      "Epoch 268/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1882 - val_loss: 0.2087\n",
      "Epoch 269/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1956 - val_loss: 0.1751\n",
      "Epoch 270/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1845 - val_loss: 0.1929\n",
      "Epoch 271/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1840 - val_loss: 0.1682\n",
      "Epoch 272/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1847 - val_loss: 0.1996\n",
      "Epoch 273/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1834 - val_loss: 0.1769\n",
      "Epoch 274/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.1848 - val_loss: 0.2977\n",
      "Epoch 275/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1886 - val_loss: 0.2202\n",
      "Epoch 276/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1876 - val_loss: 0.1687\n",
      "Epoch 277/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1822 - val_loss: 0.1667\n",
      "Epoch 278/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1819 - val_loss: 0.1680\n",
      "Epoch 279/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1788 - val_loss: 0.1600\n",
      "Epoch 280/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1812 - val_loss: 0.1887\n",
      "Epoch 281/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1823 - val_loss: 0.2819\n",
      "Epoch 282/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1816 - val_loss: 0.1725\n",
      "Epoch 283/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1819 - val_loss: 0.1961\n",
      "Epoch 284/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1762 - val_loss: 0.1619\n",
      "Epoch 285/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1765 - val_loss: 0.2291\n",
      "Epoch 286/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1929 - val_loss: 0.2423\n",
      "Epoch 287/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.2261 - val_loss: 0.1884\n",
      "Epoch 288/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1875 - val_loss: 0.1628\n",
      "Epoch 289/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.1797 - val_loss: 0.1929\n",
      "Epoch 290/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1823 - val_loss: 0.1692\n",
      "Epoch 291/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1785 - val_loss: 0.1996\n",
      "Epoch 292/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1833 - val_loss: 0.1987\n",
      "Epoch 293/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1821 - val_loss: 0.1667\n",
      "Epoch 294/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1754 - val_loss: 0.1562\n",
      "Epoch 295/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1735 - val_loss: 0.1734\n",
      "Epoch 296/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1790 - val_loss: 0.1694\n",
      "Epoch 297/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1795 - val_loss: 0.1585\n",
      "Epoch 298/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1744 - val_loss: 0.1782\n",
      "Epoch 299/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1794 - val_loss: 0.1678\n",
      "Epoch 300/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1746 - val_loss: 0.1545\n",
      "Epoch 301/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1720 - val_loss: 0.1604\n",
      "Epoch 302/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1723 - val_loss: 0.1613\n",
      "Epoch 303/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1738 - val_loss: 0.1529\n",
      "Epoch 304/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1747 - val_loss: 0.2803\n",
      "Epoch 305/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1749 - val_loss: 0.1622\n",
      "Epoch 306/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1731 - val_loss: 0.1664\n",
      "Epoch 307/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1653 - val_loss: 0.1657\n",
      "Epoch 308/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.1697 - val_loss: 0.1547\n",
      "Epoch 309/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.1693 - val_loss: 0.1495\n",
      "Epoch 310/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1685 - val_loss: 0.1552\n",
      "Epoch 311/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1693 - val_loss: 0.1613\n",
      "Epoch 312/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1688 - val_loss: 0.1520\n",
      "Epoch 313/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1695 - val_loss: 0.1631\n",
      "Epoch 314/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1652 - val_loss: 0.1867\n",
      "Epoch 315/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1692 - val_loss: 0.1823\n",
      "Epoch 316/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1700 - val_loss: 0.1715\n",
      "Epoch 317/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1687 - val_loss: 0.1587\n",
      "Epoch 318/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1712 - val_loss: 0.1564\n",
      "Epoch 319/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1685 - val_loss: 0.1487\n",
      "Epoch 320/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1668 - val_loss: 0.2389\n",
      "Epoch 321/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1674 - val_loss: 0.1537\n",
      "Epoch 322/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1606 - val_loss: 0.1563\n",
      "Epoch 323/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1629 - val_loss: 0.1445\n",
      "Epoch 324/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1596 - val_loss: 0.1452\n",
      "Epoch 325/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1575 - val_loss: 0.1618\n",
      "Epoch 326/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1613 - val_loss: 0.1908\n",
      "Epoch 327/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1631 - val_loss: 0.1679\n",
      "Epoch 328/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1612 - val_loss: 0.1722\n",
      "Epoch 329/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1624 - val_loss: 0.1988\n",
      "Epoch 330/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1718 - val_loss: 0.1612\n",
      "Epoch 331/2000\n",
      "1314/1314 [==============================] - 0s 332us/step - loss: 0.1591 - val_loss: 0.1611\n",
      "Epoch 332/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1627 - val_loss: 0.1449\n",
      "Epoch 333/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1618 - val_loss: 0.1878\n",
      "Epoch 334/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1557 - val_loss: 0.1807\n",
      "Epoch 335/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1624 - val_loss: 0.2509\n",
      "Epoch 336/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1615 - val_loss: 0.1687\n",
      "Epoch 337/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1636 - val_loss: 0.1621\n",
      "Epoch 338/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1600 - val_loss: 0.1466\n",
      "Epoch 339/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1594 - val_loss: 0.1406\n",
      "Epoch 340/2000\n",
      "1314/1314 [==============================] - 0s 296us/step - loss: 0.1582 - val_loss: 0.1877\n",
      "Epoch 341/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1589 - val_loss: 0.1671\n",
      "Epoch 342/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1610 - val_loss: 0.1543\n",
      "Epoch 343/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1620 - val_loss: 0.1684\n",
      "Epoch 344/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1646 - val_loss: 0.2014\n",
      "Epoch 345/2000\n",
      "1314/1314 [==============================] - 0s 297us/step - loss: 0.1586 - val_loss: 0.1981\n",
      "Epoch 346/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1566 - val_loss: 0.1456\n",
      "Epoch 347/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1565 - val_loss: 0.1434\n",
      "Epoch 348/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1614 - val_loss: 0.1552\n",
      "Epoch 349/2000\n",
      "1314/1314 [==============================] - 0s 314us/step - loss: 0.1605 - val_loss: 0.1938\n",
      "Epoch 350/2000\n",
      "1314/1314 [==============================] - 0s 297us/step - loss: 0.1700 - val_loss: 0.1519\n",
      "Epoch 351/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.1610 - val_loss: 0.1582\n",
      "Epoch 352/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1611 - val_loss: 0.1608\n",
      "Epoch 353/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1624 - val_loss: 0.2639\n",
      "Epoch 354/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1631 - val_loss: 0.2675\n",
      "Epoch 355/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1635 - val_loss: 0.1573\n",
      "Epoch 356/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1577 - val_loss: 0.1449\n",
      "Epoch 357/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1640 - val_loss: 0.1513\n",
      "Epoch 358/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1618 - val_loss: 0.1691\n",
      "Epoch 359/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1563 - val_loss: 0.1403\n",
      "Epoch 360/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1543 - val_loss: 0.1493\n",
      "Epoch 361/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1613 - val_loss: 0.1468\n",
      "Epoch 362/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1584 - val_loss: 0.1753\n",
      "Epoch 363/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1589 - val_loss: 0.1706\n",
      "Epoch 364/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1597 - val_loss: 0.1528\n",
      "Epoch 365/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1584 - val_loss: 0.1621\n",
      "Epoch 366/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1544 - val_loss: 0.2041\n",
      "Epoch 367/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1570 - val_loss: 0.1514\n",
      "Epoch 368/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1570 - val_loss: 0.1646\n",
      "Epoch 369/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1546 - val_loss: 0.1528\n",
      "Epoch 370/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1564 - val_loss: 0.1673\n",
      "Epoch 371/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1577 - val_loss: 0.1445\n",
      "Epoch 372/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1530 - val_loss: 0.1448\n",
      "Epoch 373/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1622 - val_loss: 0.2125\n",
      "Epoch 374/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1560 - val_loss: 0.1475\n",
      "Epoch 375/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1554 - val_loss: 0.1850\n",
      "Epoch 376/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1654 - val_loss: 0.1952\n",
      "Epoch 377/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1562 - val_loss: 0.1451\n",
      "Epoch 378/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1588 - val_loss: 0.1553\n",
      "Epoch 379/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1567 - val_loss: 0.1529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1556 - val_loss: 0.2112\n",
      "Epoch 381/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1508 - val_loss: 0.1628\n",
      "Epoch 382/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1537 - val_loss: 0.1384\n",
      "Epoch 383/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1547 - val_loss: 0.1588\n",
      "Epoch 384/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1499 - val_loss: 0.1375\n",
      "Epoch 385/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1506 - val_loss: 0.1601\n",
      "Epoch 386/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1557 - val_loss: 0.1452\n",
      "Epoch 387/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1545 - val_loss: 0.1704\n",
      "Epoch 388/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1582 - val_loss: 0.1380\n",
      "Epoch 389/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1536 - val_loss: 0.1463\n",
      "Epoch 390/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1533 - val_loss: 0.1584\n",
      "Epoch 391/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1522 - val_loss: 0.1443\n",
      "Epoch 392/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1568 - val_loss: 0.1366\n",
      "Epoch 393/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1543 - val_loss: 0.1427\n",
      "Epoch 394/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1532 - val_loss: 0.1438\n",
      "Epoch 395/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1521 - val_loss: 0.1472\n",
      "Epoch 396/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1540 - val_loss: 0.1594\n",
      "Epoch 397/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1589 - val_loss: 0.1412\n",
      "Epoch 398/2000\n",
      "1314/1314 [==============================] - 0s 297us/step - loss: 0.1503 - val_loss: 0.1514\n",
      "Epoch 399/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1502 - val_loss: 0.1594\n",
      "Epoch 400/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1517 - val_loss: 0.1451\n",
      "Epoch 401/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1492 - val_loss: 0.2715\n",
      "Epoch 402/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1512 - val_loss: 0.1620\n",
      "Epoch 403/2000\n",
      "1314/1314 [==============================] - 0s 297us/step - loss: 0.1556 - val_loss: 1.4960\n",
      "Epoch 404/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.2578 - val_loss: 0.2062\n",
      "Epoch 405/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1730 - val_loss: 0.1559\n",
      "Epoch 406/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1561 - val_loss: 0.1526\n",
      "Epoch 407/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1520 - val_loss: 0.1358\n",
      "Epoch 408/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1483 - val_loss: 0.1334\n",
      "Epoch 409/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1503 - val_loss: 0.1408\n",
      "Epoch 410/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1510 - val_loss: 0.1456\n",
      "Epoch 411/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1500 - val_loss: 0.1357\n",
      "Epoch 412/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1525 - val_loss: 0.1471\n",
      "Epoch 413/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1470 - val_loss: 0.1427\n",
      "Epoch 414/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1461 - val_loss: 0.1433\n",
      "Epoch 415/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1486 - val_loss: 0.1344\n",
      "Epoch 416/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1461 - val_loss: 0.1342\n",
      "Epoch 417/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1497 - val_loss: 0.1343\n",
      "Epoch 418/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1465 - val_loss: 0.1335\n",
      "Epoch 419/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1648 - val_loss: 0.9841\n",
      "Epoch 420/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.2495 - val_loss: 0.1971\n",
      "Epoch 421/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1753 - val_loss: 0.1447\n",
      "Epoch 422/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1578 - val_loss: 0.1453\n",
      "Epoch 423/2000\n",
      "1314/1314 [==============================] - 0s 297us/step - loss: 0.1532 - val_loss: 0.1378\n",
      "Epoch 424/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.1502 - val_loss: 0.1497\n",
      "Epoch 425/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1493 - val_loss: 0.1347\n",
      "Epoch 426/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1503 - val_loss: 0.1374\n",
      "Epoch 427/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1461 - val_loss: 0.1416\n",
      "Epoch 428/2000\n",
      "1314/1314 [==============================] - 0s 297us/step - loss: 0.1493 - val_loss: 0.1611\n",
      "Epoch 429/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1519 - val_loss: 0.1395\n",
      "Epoch 430/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1517 - val_loss: 0.1543\n",
      "Epoch 431/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1606 - val_loss: 0.1517\n",
      "Epoch 432/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1536 - val_loss: 0.1461\n",
      "Epoch 433/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1542 - val_loss: 0.1440\n",
      "Epoch 434/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1495 - val_loss: 0.1498\n",
      "Epoch 435/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1525 - val_loss: 0.1394\n",
      "Epoch 436/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1475 - val_loss: 0.1408\n",
      "Epoch 437/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1529 - val_loss: 0.1898\n",
      "Epoch 438/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1525 - val_loss: 0.1655\n",
      "Epoch 439/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1512 - val_loss: 0.1413\n",
      "Epoch 440/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1475 - val_loss: 0.1453\n",
      "Epoch 441/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1494 - val_loss: 0.1697\n",
      "Epoch 442/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1462 - val_loss: 0.1535\n",
      "Epoch 443/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1469 - val_loss: 0.2013\n",
      "Epoch 444/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1517 - val_loss: 0.1497\n",
      "Epoch 445/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1470 - val_loss: 0.1417\n",
      "Epoch 446/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1510 - val_loss: 0.2067\n",
      "Epoch 447/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1483 - val_loss: 0.1729\n",
      "Epoch 448/2000\n",
      "1314/1314 [==============================] - 0s 311us/step - loss: 0.1503 - val_loss: 0.1455\n",
      "Epoch 449/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1486 - val_loss: 0.1331\n",
      "Epoch 450/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1475 - val_loss: 0.1645\n",
      "Epoch 451/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1483 - val_loss: 0.1395\n",
      "Epoch 452/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1456 - val_loss: 0.1691\n",
      "Epoch 453/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1473 - val_loss: 0.1369\n",
      "Epoch 454/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1458 - val_loss: 0.1462\n",
      "Epoch 455/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1446 - val_loss: 0.1340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1447 - val_loss: 0.1720\n",
      "Epoch 457/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1474 - val_loss: 0.2496\n",
      "Epoch 458/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1464 - val_loss: 0.1511\n",
      "Epoch 459/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1529 - val_loss: 0.1327\n",
      "Epoch 460/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1462 - val_loss: 0.1397\n",
      "Epoch 461/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1503 - val_loss: 0.1508\n",
      "Epoch 462/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1512 - val_loss: 0.1362\n",
      "Epoch 463/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1472 - val_loss: 0.1377\n",
      "Epoch 464/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1450 - val_loss: 0.1384\n",
      "Epoch 465/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1414 - val_loss: 0.1304\n",
      "Epoch 466/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1447 - val_loss: 0.1350\n",
      "Epoch 467/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1469 - val_loss: 0.1683\n",
      "Epoch 468/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1567 - val_loss: 0.1472\n",
      "Epoch 469/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.1440 - val_loss: 0.1679\n",
      "Epoch 470/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1464 - val_loss: 0.1355\n",
      "Epoch 471/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1487 - val_loss: 0.1613\n",
      "Epoch 472/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1472 - val_loss: 0.1389\n",
      "Epoch 473/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1539 - val_loss: 0.1594\n",
      "Epoch 474/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1511 - val_loss: 0.1553\n",
      "Epoch 475/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1514 - val_loss: 0.1634\n",
      "Epoch 476/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.1506 - val_loss: 0.1438\n",
      "Epoch 477/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1446 - val_loss: 0.1489\n",
      "Epoch 478/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1425 - val_loss: 0.1662\n",
      "Epoch 479/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1466 - val_loss: 0.1707\n",
      "Epoch 480/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1429 - val_loss: 0.1374\n",
      "Epoch 481/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1407 - val_loss: 0.1338\n",
      "Epoch 482/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1397 - val_loss: 0.1444\n",
      "Epoch 483/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1418 - val_loss: 0.1715\n",
      "Epoch 484/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1441 - val_loss: 0.1309\n",
      "Epoch 485/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1394 - val_loss: 0.1275\n",
      "Epoch 486/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1450 - val_loss: 0.1365\n",
      "Epoch 487/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1511 - val_loss: 0.1336\n",
      "Epoch 488/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1474 - val_loss: 0.2243\n",
      "Epoch 489/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.1426 - val_loss: 0.1340\n",
      "Epoch 490/2000\n",
      "1314/1314 [==============================] - 0s 309us/step - loss: 0.1473 - val_loss: 0.1769\n",
      "Epoch 491/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.1484 - val_loss: 0.1365\n",
      "Epoch 492/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.1462 - val_loss: 0.1519\n",
      "Epoch 493/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1457 - val_loss: 0.1726\n",
      "Epoch 494/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.1440 - val_loss: 0.1380\n",
      "Epoch 495/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1471 - val_loss: 0.1691\n",
      "Epoch 496/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1439 - val_loss: 0.1536\n",
      "Epoch 497/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1425 - val_loss: 0.1309\n",
      "Epoch 498/2000\n",
      "1314/1314 [==============================] - 0s 311us/step - loss: 0.1408 - val_loss: 0.1333\n",
      "Epoch 499/2000\n",
      "1314/1314 [==============================] - 0s 317us/step - loss: 0.1443 - val_loss: 0.1304\n",
      "Epoch 500/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1465 - val_loss: 0.1286\n",
      "Epoch 501/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1447 - val_loss: 0.1321\n",
      "Epoch 502/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1402 - val_loss: 0.1339\n",
      "Epoch 503/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1461 - val_loss: 0.1317\n",
      "Epoch 504/2000\n",
      "1314/1314 [==============================] - 1s 428us/step - loss: 0.1385 - val_loss: 0.1608\n",
      "Epoch 505/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.1446 - val_loss: 0.1292\n",
      "Epoch 506/2000\n",
      "1314/1314 [==============================] - 0s 316us/step - loss: 0.1422 - val_loss: 0.1282\n",
      "Epoch 507/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1413 - val_loss: 0.1421\n",
      "Epoch 508/2000\n",
      "1314/1314 [==============================] - 0s 313us/step - loss: 0.1403 - val_loss: 0.1282\n",
      "Epoch 509/2000\n",
      "1314/1314 [==============================] - 0s 312us/step - loss: 0.1435 - val_loss: 0.1394\n",
      "Epoch 510/2000\n",
      "1314/1314 [==============================] - 0s 337us/step - loss: 0.1428 - val_loss: 0.1257\n",
      "Epoch 511/2000\n",
      "1314/1314 [==============================] - 0s 317us/step - loss: 0.1438 - val_loss: 0.1314\n",
      "Epoch 512/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1404 - val_loss: 0.1348\n",
      "Epoch 513/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1450 - val_loss: 0.1283\n",
      "Epoch 514/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1393 - val_loss: 0.1568\n",
      "Epoch 515/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1411 - val_loss: 0.1282\n",
      "Epoch 516/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1374 - val_loss: 0.1512\n",
      "Epoch 517/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1417 - val_loss: 0.1261\n",
      "Epoch 518/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1402 - val_loss: 0.1521\n",
      "Epoch 519/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1469 - val_loss: 0.1432\n",
      "Epoch 520/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1387 - val_loss: 0.1330\n",
      "Epoch 521/2000\n",
      "1314/1314 [==============================] - 0s 336us/step - loss: 0.1450 - val_loss: 0.1280\n",
      "Epoch 522/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1431 - val_loss: 0.1281\n",
      "Epoch 523/2000\n",
      "1314/1314 [==============================] - 0s 326us/step - loss: 0.1406 - val_loss: 0.1428\n",
      "Epoch 524/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1397 - val_loss: 0.1503\n",
      "Epoch 525/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1392 - val_loss: 0.1383\n",
      "Epoch 526/2000\n",
      "1314/1314 [==============================] - 0s 306us/step - loss: 0.1370 - val_loss: 0.1323\n",
      "Epoch 527/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1429 - val_loss: 0.2224\n",
      "Epoch 528/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1472 - val_loss: 0.1682\n",
      "Epoch 529/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.1462 - val_loss: 0.1454\n",
      "Epoch 530/2000\n",
      "1314/1314 [==============================] - 0s 310us/step - loss: 0.1435 - val_loss: 0.1664\n",
      "Epoch 531/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.1384 - val_loss: 0.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1471 - val_loss: 0.1350\n",
      "Epoch 533/2000\n",
      "1314/1314 [==============================] - 0s 299us/step - loss: 0.1469 - val_loss: 0.1308\n",
      "Epoch 534/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.1452 - val_loss: 0.1321\n",
      "Epoch 535/2000\n",
      "1314/1314 [==============================] - 0s 342us/step - loss: 0.1417 - val_loss: 0.1349\n",
      "Epoch 536/2000\n",
      "1314/1314 [==============================] - 0s 308us/step - loss: 0.1414 - val_loss: 0.1438\n",
      "Epoch 537/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1403 - val_loss: 0.1290\n",
      "Epoch 538/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1369 - val_loss: 0.1307\n",
      "Epoch 539/2000\n",
      "1314/1314 [==============================] - 0s 296us/step - loss: 0.1393 - val_loss: 0.1342\n",
      "Epoch 540/2000\n",
      "1314/1314 [==============================] - 0s 304us/step - loss: 0.1376 - val_loss: 0.1358\n",
      "Epoch 541/2000\n",
      "1314/1314 [==============================] - 0s 305us/step - loss: 0.1461 - val_loss: 0.1299\n",
      "Epoch 542/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1408 - val_loss: 0.1406\n",
      "Epoch 543/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1441 - val_loss: 0.1323\n",
      "Epoch 544/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1492 - val_loss: 0.1810\n",
      "Epoch 545/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1448 - val_loss: 0.1380\n",
      "Epoch 546/2000\n",
      "1314/1314 [==============================] - 0s 297us/step - loss: 0.1374 - val_loss: 0.1458\n",
      "Epoch 547/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1404 - val_loss: 0.1344\n",
      "Epoch 548/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1443 - val_loss: 0.1327\n",
      "Epoch 549/2000\n",
      "1314/1314 [==============================] - 0s 298us/step - loss: 0.1409 - val_loss: 0.1267\n",
      "Epoch 550/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1423 - val_loss: 0.1322\n",
      "Epoch 551/2000\n",
      "1314/1314 [==============================] - 0s 303us/step - loss: 0.1402 - val_loss: 0.1372\n",
      "Epoch 552/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1394 - val_loss: 0.1431\n",
      "Epoch 553/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1454 - val_loss: 0.1286\n",
      "Epoch 554/2000\n",
      "1314/1314 [==============================] - 0s 301us/step - loss: 0.1365 - val_loss: 0.1292\n",
      "Epoch 555/2000\n",
      "1314/1314 [==============================] - 0s 302us/step - loss: 0.1356 - val_loss: 0.1184\n",
      "Epoch 556/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1399 - val_loss: 0.1266\n",
      "Epoch 557/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1348 - val_loss: 0.1267\n",
      "Epoch 558/2000\n",
      "1314/1314 [==============================] - 0s 300us/step - loss: 0.1344 - val_loss: 0.1298\n",
      "Epoch 559/2000\n",
      "1314/1314 [==============================] - 0s 307us/step - loss: 0.1321 - val_loss: 0.2375\n",
      "Epoch 560/2000\n",
      "1314/1314 [==============================] - 1s 680us/step - loss: 0.1589 - val_loss: 0.1352\n",
      "Epoch 561/2000\n",
      "1314/1314 [==============================] - 1s 775us/step - loss: 0.1457 - val_loss: 0.1269\n",
      "Epoch 562/2000\n",
      "1314/1314 [==============================] - 1s 398us/step - loss: 0.1434 - val_loss: 0.1370\n",
      "Epoch 563/2000\n",
      "1314/1314 [==============================] - 0s 343us/step - loss: 0.1431 - val_loss: 0.1290\n",
      "Epoch 564/2000\n",
      "1314/1314 [==============================] - 1s 442us/step - loss: 0.1382 - val_loss: 0.1338\n",
      "Epoch 565/2000\n",
      "1314/1314 [==============================] - 1s 531us/step - loss: 0.1382 - val_loss: 0.1208\n",
      "Epoch 566/2000\n",
      "1314/1314 [==============================] - 1s 501us/step - loss: 0.1374 - val_loss: 0.1476\n",
      "Epoch 567/2000\n",
      "1314/1314 [==============================] - 1s 478us/step - loss: 0.1301 - val_loss: 0.1212\n",
      "Epoch 568/2000\n",
      "1314/1314 [==============================] - 1s 492us/step - loss: 0.1321 - val_loss: 0.1262\n",
      "Epoch 569/2000\n",
      "1314/1314 [==============================] - 1s 442us/step - loss: 0.1319 - val_loss: 0.1705\n",
      "Epoch 570/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 0.1401 - val_loss: 0.1226\n",
      "Epoch 571/2000\n",
      "1314/1314 [==============================] - 0s 328us/step - loss: 0.1408 - val_loss: 0.1371\n",
      "Epoch 572/2000\n",
      "1314/1314 [==============================] - 0s 335us/step - loss: 0.1345 - val_loss: 0.1818\n",
      "Epoch 573/2000\n",
      "1314/1314 [==============================] - 0s 343us/step - loss: 0.1312 - val_loss: 0.1190\n",
      "Epoch 574/2000\n",
      "1314/1314 [==============================] - 0s 333us/step - loss: 0.1372 - val_loss: 0.1271\n",
      "Epoch 575/2000\n",
      "1314/1314 [==============================] - 0s 368us/step - loss: 0.1325 - val_loss: 0.1273\n",
      "Epoch 576/2000\n",
      "1314/1314 [==============================] - 1s 405us/step - loss: 0.1348 - val_loss: 0.1300\n",
      "Epoch 577/2000\n",
      "1314/1314 [==============================] - 1s 388us/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 578/2000\n",
      "1314/1314 [==============================] - 1s 407us/step - loss: 0.1366 - val_loss: 0.1223\n",
      "Epoch 579/2000\n",
      "1314/1314 [==============================] - 1s 429us/step - loss: 0.1382 - val_loss: 0.1372\n",
      "Epoch 580/2000\n",
      "1314/1314 [==============================] - 1s 405us/step - loss: 0.1350 - val_loss: 0.1303\n",
      "Epoch 581/2000\n",
      "1314/1314 [==============================] - 0s 363us/step - loss: 0.1356 - val_loss: 0.1322\n",
      "Epoch 582/2000\n",
      "1314/1314 [==============================] - 0s 352us/step - loss: 0.1337 - val_loss: 0.1184\n",
      "Epoch 583/2000\n",
      "1314/1314 [==============================] - 0s 343us/step - loss: 0.1322 - val_loss: 0.1352\n",
      "Epoch 584/2000\n",
      "1314/1314 [==============================] - 0s 353us/step - loss: 0.1331 - val_loss: 0.1193\n",
      "Epoch 585/2000\n",
      "1314/1314 [==============================] - 0s 354us/step - loss: 0.1358 - val_loss: 0.1227\n",
      "Epoch 586/2000\n",
      "1314/1314 [==============================] - 1s 388us/step - loss: 0.1355 - val_loss: 0.1203\n",
      "Epoch 587/2000\n",
      "1314/1314 [==============================] - 1s 385us/step - loss: 0.1345 - val_loss: 0.1185\n",
      "Epoch 588/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.1371 - val_loss: 0.1359\n",
      "Epoch 589/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 0.1377 - val_loss: 0.1251\n",
      "Epoch 590/2000\n",
      "1314/1314 [==============================] - 0s 380us/step - loss: 0.1346 - val_loss: 0.1331\n",
      "Epoch 591/2000\n",
      "1314/1314 [==============================] - 1s 385us/step - loss: 0.1328 - val_loss: 0.1264\n",
      "Epoch 592/2000\n",
      "1314/1314 [==============================] - 0s 365us/step - loss: 0.1351 - val_loss: 0.1317\n",
      "Epoch 593/2000\n",
      "1314/1314 [==============================] - 0s 353us/step - loss: 0.1380 - val_loss: 0.1258\n",
      "Epoch 594/2000\n",
      "1314/1314 [==============================] - 0s 368us/step - loss: 0.1334 - val_loss: 0.1457\n",
      "Epoch 595/2000\n",
      "1314/1314 [==============================] - 0s 376us/step - loss: 0.1301 - val_loss: 0.1172\n",
      "Epoch 596/2000\n",
      "1314/1314 [==============================] - 0s 343us/step - loss: 0.1324 - val_loss: 0.1316\n",
      "Epoch 597/2000\n",
      "1314/1314 [==============================] - 0s 354us/step - loss: 0.1382 - val_loss: 0.1315\n",
      "Epoch 598/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.1362 - val_loss: 0.1254\n",
      "Epoch 599/2000\n",
      "1314/1314 [==============================] - 0s 362us/step - loss: 0.1331 - val_loss: 0.1225\n",
      "Epoch 600/2000\n",
      "1314/1314 [==============================] - 0s 349us/step - loss: 0.1321 - val_loss: 0.1649\n",
      "Epoch 601/2000\n",
      "1314/1314 [==============================] - 0s 373us/step - loss: 0.1311 - val_loss: 0.1420\n",
      "Epoch 602/2000\n",
      "1314/1314 [==============================] - 0s 367us/step - loss: 0.1472 - val_loss: 0.2027\n",
      "Epoch 603/2000\n",
      "1314/1314 [==============================] - 1s 388us/step - loss: 0.1576 - val_loss: 0.1545\n",
      "Epoch 604/2000\n",
      "1314/1314 [==============================] - 0s 365us/step - loss: 0.1412 - val_loss: 0.1356\n",
      "Epoch 605/2000\n",
      "1314/1314 [==============================] - 0s 358us/step - loss: 0.1378 - val_loss: 0.1247\n",
      "Epoch 606/2000\n",
      "1314/1314 [==============================] - 0s 374us/step - loss: 0.1340 - val_loss: 0.1235\n",
      "Epoch 607/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.1321 - val_loss: 0.1202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608/2000\n",
      "1314/1314 [==============================] - 0s 322us/step - loss: 0.1286 - val_loss: 0.1219\n",
      "Epoch 609/2000\n",
      "1314/1314 [==============================] - 0s 315us/step - loss: 0.1333 - val_loss: 0.1226\n",
      "Epoch 610/2000\n",
      "1314/1314 [==============================] - 0s 336us/step - loss: 0.1340 - val_loss: 0.1201\n",
      "Epoch 611/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.1326 - val_loss: 0.1191\n",
      "Epoch 612/2000\n",
      "1314/1314 [==============================] - 0s 329us/step - loss: 0.1332 - val_loss: 0.1268\n",
      "Epoch 613/2000\n",
      "1314/1314 [==============================] - 0s 325us/step - loss: 0.1311 - val_loss: 0.1238\n",
      "Epoch 614/2000\n",
      "1314/1314 [==============================] - 0s 332us/step - loss: 0.1337 - val_loss: 0.1290\n",
      "Epoch 615/2000\n",
      "1314/1314 [==============================] - 0s 330us/step - loss: 0.1359 - val_loss: 0.1278\n",
      "Epoch 616/2000\n",
      "1314/1314 [==============================] - 0s 324us/step - loss: 0.1307 - val_loss: 0.1299\n",
      "Epoch 617/2000\n",
      "1314/1314 [==============================] - 0s 325us/step - loss: 0.1298 - val_loss: 0.1335\n",
      "Epoch 618/2000\n",
      "1314/1314 [==============================] - 0s 375us/step - loss: 0.1297 - val_loss: 0.1442\n",
      "Epoch 619/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 0.1336 - val_loss: 0.1170\n",
      "Epoch 620/2000\n",
      "1314/1314 [==============================] - 0s 351us/step - loss: 0.1324 - val_loss: 0.1300\n",
      "Epoch 621/2000\n",
      "1314/1314 [==============================] - 0s 346us/step - loss: 0.1301 - val_loss: 0.1313\n",
      "Epoch 622/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.1292 - val_loss: 0.1363\n",
      "Epoch 623/2000\n",
      "1314/1314 [==============================] - 0s 349us/step - loss: 0.1316 - val_loss: 0.1381\n",
      "Epoch 624/2000\n",
      "1314/1314 [==============================] - 0s 342us/step - loss: 0.1352 - val_loss: 0.1332\n",
      "Epoch 625/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.1283 - val_loss: 0.1194\n",
      "Epoch 626/2000\n",
      "1314/1314 [==============================] - 0s 346us/step - loss: 0.1283 - val_loss: 0.1180\n",
      "Epoch 627/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.1276 - val_loss: 0.1187\n",
      "Epoch 628/2000\n",
      "1314/1314 [==============================] - 0s 328us/step - loss: 0.1284 - val_loss: 0.1202\n",
      "Epoch 629/2000\n",
      "1314/1314 [==============================] - 0s 344us/step - loss: 0.1312 - val_loss: 0.1195\n",
      "Epoch 630/2000\n",
      "1314/1314 [==============================] - 0s 343us/step - loss: 0.1323 - val_loss: 0.1308\n",
      "Epoch 631/2000\n",
      "1314/1314 [==============================] - 0s 362us/step - loss: 0.1309 - val_loss: 0.1194\n",
      "Epoch 632/2000\n",
      "1314/1314 [==============================] - 0s 350us/step - loss: 0.1303 - val_loss: 0.1317\n",
      "Epoch 633/2000\n",
      "1314/1314 [==============================] - 0s 361us/step - loss: 0.1298 - val_loss: 0.1295\n",
      "Epoch 634/2000\n",
      "1314/1314 [==============================] - 0s 350us/step - loss: 0.1313 - val_loss: 0.1221\n",
      "Epoch 635/2000\n",
      "1314/1314 [==============================] - 0s 356us/step - loss: 0.1283 - val_loss: 0.1303\n",
      "Epoch 636/2000\n",
      "1314/1314 [==============================] - 1s 598us/step - loss: 0.1305 - val_loss: 0.1296\n",
      "Epoch 637/2000\n",
      "1314/1314 [==============================] - 1s 413us/step - loss: 0.1273 - val_loss: 0.1218\n",
      "Epoch 638/2000\n",
      "1314/1314 [==============================] - 0s 378us/step - loss: 0.1356 - val_loss: 0.1474\n",
      "Epoch 639/2000\n",
      "1314/1314 [==============================] - 1s 487us/step - loss: 0.1335 - val_loss: 0.1223\n",
      "Epoch 640/2000\n",
      "1314/1314 [==============================] - 1s 442us/step - loss: 0.1326 - val_loss: 0.1254\n",
      "Epoch 641/2000\n",
      "1314/1314 [==============================] - 1s 445us/step - loss: 0.1304 - val_loss: 0.1191\n",
      "Epoch 642/2000\n",
      "1314/1314 [==============================] - 1s 384us/step - loss: 0.1277 - val_loss: 0.1169\n",
      "Epoch 643/2000\n",
      "1314/1314 [==============================] - 1s 391us/step - loss: 0.1340 - val_loss: 0.1174\n",
      "Epoch 644/2000\n",
      "1314/1314 [==============================] - 1s 401us/step - loss: 0.1274 - val_loss: 0.1167\n",
      "Epoch 645/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.1282 - val_loss: 0.1345\n",
      "Epoch 646/2000\n",
      "1314/1314 [==============================] - 0s 319us/step - loss: 0.1351 - val_loss: 0.1182\n",
      "Epoch 647/2000\n",
      "1314/1314 [==============================] - 0s 331us/step - loss: 0.1341 - val_loss: 0.1546\n",
      "Epoch 648/2000\n",
      "1314/1314 [==============================] - 0s 320us/step - loss: 0.1288 - val_loss: 0.1470\n",
      "Epoch 649/2000\n",
      "1314/1314 [==============================] - 0s 345us/step - loss: 0.1319 - val_loss: 0.1364\n",
      "Epoch 650/2000\n",
      "1314/1314 [==============================] - 0s 341us/step - loss: 0.1303 - val_loss: 0.1219\n",
      "Epoch 651/2000\n",
      "1314/1314 [==============================] - 0s 340us/step - loss: 0.1299 - val_loss: 0.1212\n",
      "Epoch 652/2000\n",
      "1314/1314 [==============================] - 0s 347us/step - loss: 0.1295 - val_loss: 0.1247\n",
      "Epoch 653/2000\n",
      "1314/1314 [==============================] - 0s 314us/step - loss: 0.1310 - val_loss: 0.1169\n",
      "Epoch 654/2000\n",
      "1314/1314 [==============================] - 0s 329us/step - loss: 0.1304 - val_loss: 0.1233\n",
      "Epoch 655/2000\n",
      "1314/1314 [==============================] - 0s 320us/step - loss: 0.1269 - val_loss: 0.1753\n",
      "Epoch 656/2000\n",
      "1314/1314 [==============================] - 0s 327us/step - loss: 0.1645 - val_loss: 0.1969\n",
      "Epoch 657/2000\n",
      "1314/1314 [==============================] - 1s 484us/step - loss: 0.1703 - val_loss: 0.1386\n",
      "Epoch 658/2000\n",
      "1314/1314 [==============================] - 1s 424us/step - loss: 0.1691 - val_loss: 0.1299\n",
      "Epoch 659/2000\n",
      "1314/1314 [==============================] - 1s 444us/step - loss: 0.1404 - val_loss: 0.1396\n",
      "Epoch 660/2000\n",
      "1314/1314 [==============================] - 1s 463us/step - loss: 0.1313 - val_loss: 0.1331\n",
      "Epoch 661/2000\n",
      "1314/1314 [==============================] - 1s 462us/step - loss: 0.1405 - val_loss: 0.1352\n",
      "Epoch 662/2000\n",
      "1314/1314 [==============================] - 1s 415us/step - loss: 0.1320 - val_loss: 0.1267\n",
      "Epoch 663/2000\n",
      "1314/1314 [==============================] - 1s 426us/step - loss: 0.1367 - val_loss: 0.1192\n",
      "Epoch 664/2000\n",
      "1314/1314 [==============================] - 1s 462us/step - loss: 0.1294 - val_loss: 0.1252\n",
      "Epoch 665/2000\n",
      "1314/1314 [==============================] - 1s 474us/step - loss: 0.1329 - val_loss: 0.1236\n",
      "Epoch 666/2000\n",
      "1314/1314 [==============================] - 1s 456us/step - loss: 0.1263 - val_loss: 0.1216\n",
      "Epoch 667/2000\n",
      "1314/1314 [==============================] - 1s 448us/step - loss: 0.1295 - val_loss: 0.1456\n",
      "Epoch 668/2000\n",
      "1314/1314 [==============================] - 1s 443us/step - loss: 0.1316 - val_loss: 0.1225\n",
      "Epoch 669/2000\n",
      "1314/1314 [==============================] - 1s 485us/step - loss: 0.1310 - val_loss: 0.1233\n",
      "Epoch 670/2000\n",
      "1314/1314 [==============================] - 1s 457us/step - loss: 0.1301 - val_loss: 0.1254\n",
      "Epoch 671/2000\n",
      "1314/1314 [==============================] - 1s 448us/step - loss: 0.1283 - val_loss: 0.1602\n",
      "Epoch 672/2000\n",
      "1314/1314 [==============================] - 1s 490us/step - loss: 0.1342 - val_loss: 0.1357\n",
      "Epoch 673/2000\n",
      "1314/1314 [==============================] - 1s 462us/step - loss: 0.1324 - val_loss: 0.1276\n",
      "Epoch 674/2000\n",
      "1314/1314 [==============================] - 1s 475us/step - loss: 0.1277 - val_loss: 0.1258\n",
      "Epoch 675/2000\n",
      "1314/1314 [==============================] - 1s 433us/step - loss: 0.1256 - val_loss: 0.1277\n",
      "Epoch 676/2000\n",
      "1314/1314 [==============================] - 1s 454us/step - loss: 0.1230 - val_loss: 0.1152\n",
      "Epoch 677/2000\n",
      "1314/1314 [==============================] - 1s 436us/step - loss: 0.1247 - val_loss: 0.1197\n",
      "Epoch 678/2000\n",
      "1314/1314 [==============================] - 1s 397us/step - loss: 0.1274 - val_loss: 0.1232\n",
      "Epoch 679/2000\n",
      "1314/1314 [==============================] - 1s 388us/step - loss: 0.1268 - val_loss: 0.1220\n",
      "Epoch 680/2000\n",
      "1314/1314 [==============================] - 1s 412us/step - loss: 0.1292 - val_loss: 0.1188\n",
      "Epoch 681/2000\n",
      "1314/1314 [==============================] - 1s 562us/step - loss: 0.1271 - val_loss: 0.1170\n",
      "Epoch 682/2000\n",
      "1314/1314 [==============================] - 1s 507us/step - loss: 0.1252 - val_loss: 0.1106\n",
      "Epoch 683/2000\n",
      "1314/1314 [==============================] - 1s 592us/step - loss: 0.1276 - val_loss: 0.1165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/2000\n",
      "1314/1314 [==============================] - 1s 533us/step - loss: 0.1291 - val_loss: 0.1141\n",
      "Epoch 685/2000\n",
      "1314/1314 [==============================] - 1s 488us/step - loss: 0.1265 - val_loss: 0.1242\n",
      "Epoch 686/2000\n",
      "1314/1314 [==============================] - 1s 648us/step - loss: 0.1274 - val_loss: 0.1147\n",
      "Epoch 687/2000\n",
      "1314/1314 [==============================] - 1s 630us/step - loss: 0.1274 - val_loss: 0.1138\n",
      "Epoch 688/2000\n",
      "1314/1314 [==============================] - 1s 457us/step - loss: 0.1327 - val_loss: 0.1193\n",
      "Epoch 689/2000\n",
      "1314/1314 [==============================] - 0s 375us/step - loss: 0.1253 - val_loss: 0.1147\n",
      "Epoch 690/2000\n",
      "1314/1314 [==============================] - 1s 386us/step - loss: 0.1272 - val_loss: 0.1152\n",
      "Epoch 691/2000\n",
      "1314/1314 [==============================] - 0s 378us/step - loss: 0.1251 - val_loss: 0.1212\n",
      "Epoch 692/2000\n",
      "1314/1314 [==============================] - 0s 360us/step - loss: 0.1269 - val_loss: 0.1184\n",
      "Epoch 693/2000\n",
      "1314/1314 [==============================] - 1s 438us/step - loss: 0.1292 - val_loss: 0.1113\n",
      "Epoch 694/2000\n",
      "1314/1314 [==============================] - 1s 442us/step - loss: 0.1281 - val_loss: 0.1229\n",
      "Epoch 695/2000\n",
      "1314/1314 [==============================] - 1s 458us/step - loss: 0.1264 - val_loss: 0.1252\n",
      "Epoch 696/2000\n",
      "1314/1314 [==============================] - 1s 466us/step - loss: 0.1303 - val_loss: 0.1157\n",
      "Epoch 697/2000\n",
      "1314/1314 [==============================] - 1s 486us/step - loss: 0.1271 - val_loss: 0.1228\n",
      "Epoch 698/2000\n",
      "1314/1314 [==============================] - 1s 451us/step - loss: 0.1307 - val_loss: 0.1578\n",
      "Epoch 699/2000\n",
      "1314/1314 [==============================] - 1s 442us/step - loss: 0.1240 - val_loss: 0.1156\n",
      "Epoch 700/2000\n",
      " 976/1314 [=====================>........] - ETA: 0s - loss: 0.1257"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-dd46845b19f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m error = model.fit(x_scaled,y_train,\n\u001b[1;32m      2\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                   validation_steps=None,epochs=2000,verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error = model.fit(x_scaled,y_train,\n",
    "                  batch_size=8,validation_split=0.1,\n",
    "                  validation_steps=None,epochs=2000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121df9ac8>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt8AAAHxCAYAAAC1RNAfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZkT4BgCAGRG+AQBgRoRvAACYkf8fhHd+ou2+RJQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1218f8320>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 367
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13623.250801316348"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_scaled)\n",
    "metrics.mean_absolute_error(np.exp(y_train),np.exp(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.077225619201409287"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_ID\n",
    "sub['SalePrice'] = np.exp(model.predict(std_x.transform(test.values)))\n",
    "sub.to_csv('submission_nn_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
