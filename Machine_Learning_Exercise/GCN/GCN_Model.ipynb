{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How to Do Deep Learning on Graphs with Graph Convolutional Networks](https://github.com/TobiasSkovgaardJepsen/posts/blob/master/HowToDoDeepLearningOnGraphsWithGraphConvolutionalNetworks/Part2_SemiSupervisedLearningWithSpectralGraphConvolutions/notebook.ipynb)\n",
    "## Part 2: Semi-Supervised Learning with Spectral Graph Convolutions\n",
    "This notebook accompanies my Medium article with the above title for readers to try out and explore graph convolutional networks for themselves. You can find the article [here](https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0). To run the notebook, install the packages specified in the accompanying ```requirements.txt``` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Karate Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcnclass import SpectralRule, LogisticRegressor, load_karate_club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import to_numpy_matrix, degree_centrality, betweenness_centrality, shortest_path_length\n",
    "import mxnet.ndarray as nd\n",
    "\n",
    "zkc = load_karate_club()\n",
    "\n",
    "A = to_numpy_matrix(zkc.network)\n",
    "A = nd.array(A)\n",
    "\n",
    "X_train = zkc.X_train.flatten()\n",
    "y_train = zkc.y_train\n",
    "X_test = zkc.X_test.flatten()\n",
    "y_test = zkc.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import HybridBlock\n",
    "from mxnet.gluon.nn import Activation\n",
    "import mxnet.ndarray as nd\n",
    "\n",
    "# class SpectralRule(HybridBlock):\n",
    "#     def __init__(self, A, in_units, out_units, activation='relu', **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         I = nd.eye(*A.shape)\n",
    "#         A_hat = A.copy() + I\n",
    "\n",
    "#         D = nd.sum(A_hat, axis=0)\n",
    "#         D_inv = D**-0.5\n",
    "#         D_inv = nd.diag(D_inv)\n",
    "\n",
    "#         A_hat = D_inv * A_hat * D_inv\n",
    "        \n",
    "#         self.in_units, self.out_units = in_units, out_units\n",
    "        \n",
    "#         with self.name_scope():\n",
    "#             self.A_hat = self.params.get_constant('A_hat', A_hat)\n",
    "#             self.W = self.params.get(\n",
    "#                 'W', shape=(self.in_units, self.out_units)\n",
    "#             )\n",
    "#             if activation == 'identity':\n",
    "#                 self.activation = lambda X: X\n",
    "#             else:\n",
    "#                 self.activation = Activation(activation)\n",
    "\n",
    "#     def hybrid_forward(self, F, X, A_hat, W):\n",
    "#         aggregate = F.dot(A_hat, X)\n",
    "#         propagate = self.activation(\n",
    "#             F.dot(aggregate, W))\n",
    "#         return propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor(HybridBlock):\n",
    "    def __init__(self, in_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.w = self.params.get(\n",
    "                'w', shape=(1, in_units)\n",
    "            )\n",
    "\n",
    "            self.b = self.params.get(\n",
    "                'b', shape=(1, 1)\n",
    "            )\n",
    "\n",
    "    def hybrid_forward(self, F, X, w, b):\n",
    "        # Change shape of b to comply with MXnet addition API\n",
    "        b = F.broadcast_axis(b, axis=(0,1), size=(34, 1))\n",
    "        y = F.dot(X, w, transpose_b=True) + b\n",
    "\n",
    "        return F.sigmoid(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.nn import HybridSequential, Activation\n",
    "from mxnet.ndarray import array\n",
    "from mxnet.initializer import One, Uniform, Xavier\n",
    "from mxnet.gluon.loss import SigmoidBinaryCrossEntropyLoss\n",
    "\n",
    "def build_features(A, X):\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh'),] # Format: (units in layer, activation function)\n",
    "    in_units = in_units=X.shape[1]\n",
    "  \n",
    "    features = HybridSequential()\n",
    "    with features.name_scope():\n",
    "        for i, (layer_size, activation_func) in enumerate(hidden_layer_specs):\n",
    "            layer = SpectralRule(\n",
    "                A, in_units=in_units, out_units=layer_size, \n",
    "                activation=activation_func)\n",
    "            features.add(layer)\n",
    "\n",
    "            in_units = layer_size\n",
    "    return features, in_units\n",
    "\n",
    "def build_model(A, X):\n",
    "    model = HybridSequential()\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh')]\n",
    "    in_units = in_units=X.shape[1]\n",
    "\n",
    "    with model.name_scope():\n",
    "        features, out_units = build_features(A, X)\n",
    "        model.add(features)\n",
    "\n",
    "        classifier = LogisticRegressor(out_units)\n",
    "        model.add(classifier)\n",
    "\n",
    "    model.hybridize()\n",
    "    model.initialize(Uniform(1))\n",
    "\n",
    "    return model, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Identity Matrix as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = I = nd.eye(*A.shape)\n",
    "model_1, features_1 = build_model(A, X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.67846113]\n",
       " [0.678365  ]\n",
       " [0.6784515 ]\n",
       " [0.67865455]\n",
       " [0.6789896 ]\n",
       " [0.6784498 ]\n",
       " [0.67840236]\n",
       " [0.6778774 ]\n",
       " [0.67806447]\n",
       " [0.6787555 ]\n",
       " [0.6798172 ]\n",
       " [0.6771738 ]\n",
       " [0.6783973 ]\n",
       " [0.67728937]\n",
       " [0.6778644 ]\n",
       " [0.67681897]\n",
       " [0.67838305]\n",
       " [0.67841774]\n",
       " [0.67886305]\n",
       " [0.6782841 ]\n",
       " [0.6777961 ]\n",
       " [0.6784021 ]\n",
       " [0.6793397 ]\n",
       " [0.67845035]\n",
       " [0.67771035]\n",
       " [0.6787817 ]\n",
       " [0.67817426]\n",
       " [0.6773858 ]\n",
       " [0.6777696 ]\n",
       " [0.678165  ]\n",
       " [0.6781931 ]\n",
       " [0.6786611 ]\n",
       " [0.6782598 ]\n",
       " [0.67848647]]\n",
       "<NDArray 34x1 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1(X_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Distance to Administrator and Instructor as Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = nd.zeros((A.shape[0], 2))\n",
    "node_distance_instructor = shortest_path_length(zkc.network, target=33)\n",
    "node_distance_administrator = shortest_path_length(zkc.network, target=0)\n",
    "\n",
    "for node in zkc.network.nodes():\n",
    "    X_2[node][0] = node_distance_administrator[node]\n",
    "    X_2[node][1] = node_distance_instructor[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.41898128]\n",
       " [0.42066953]\n",
       " [0.4202371 ]\n",
       " [0.42225876]\n",
       " [0.42629537]\n",
       " [0.42489824]\n",
       " [0.42482445]\n",
       " [0.42436835]\n",
       " [0.42339927]\n",
       " [0.42722285]\n",
       " [0.43601376]\n",
       " [0.42917323]\n",
       " [0.42348605]\n",
       " [0.43088672]\n",
       " [0.42715982]\n",
       " [0.43249366]\n",
       " [0.42259842]\n",
       " [0.42457488]\n",
       " [0.4318612 ]\n",
       " [0.42471617]\n",
       " [0.42861357]\n",
       " [0.41973785]\n",
       " [0.43193817]\n",
       " [0.4189893 ]\n",
       " [0.43009412]\n",
       " [0.43060946]\n",
       " [0.4311095 ]\n",
       " [0.4307683 ]\n",
       " [0.43079725]\n",
       " [0.42400852]\n",
       " [0.4274449 ]\n",
       " [0.42517978]\n",
       " [0.42701358]\n",
       " [0.43231156]]\n",
       "<NDArray 34x1 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = nd.concat(X_1, X_2)\n",
    "model_2, features_2 = build_model(A, X_2)\n",
    "model_2(X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 83 µs, total: 85 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from mxnet import autograd\n",
    "from mxnet.gluon import Trainer\n",
    "from mxnet.ndarray import sum as ndsum\n",
    "import numpy as np\n",
    "\n",
    "def train(model, features, X, X_train, y_train, epochs):\n",
    "    cross_entropy = SigmoidBinaryCrossEntropyLoss(from_sigmoid=True)\n",
    "    trainer = Trainer(model.collect_params(), 'sgd', {'learning_rate': 0.001, 'momentum': 1})\n",
    "\n",
    "    feature_representations = [features(X).asnumpy()]\n",
    "\n",
    "    for e in range(1, epochs + 1):\n",
    "        cum_loss = 0\n",
    "        cum_preds = []\n",
    "\n",
    "        for i, x in enumerate(X_train):\n",
    "            y = array(y_train)[i]\n",
    "            with autograd.record():\n",
    "                preds = model(X)[x]\n",
    "                loss = cross_entropy(preds, y)\n",
    "            loss.backward()\n",
    "            trainer.step(1)\n",
    "\n",
    "            cum_loss += loss[0].asscalar()\n",
    "            cum_preds += [preds[0].asscalar()]\n",
    "\n",
    "        feature_representations.append(features(X).asnumpy())\n",
    "            \n",
    "        if (e % (epochs//10)) == 0:\n",
    "            print(f\"Epoch {e}/{epochs} -- Loss: {cum_loss: .4f}\")\n",
    "            print(cum_preds)\n",
    "    return feature_representations\n",
    "\n",
    "def predict(model, X, nodes):\n",
    "    preds = model(X)[nodes].asnumpy().flatten()\n",
    "    return  np.where(preds >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridSequential(\n",
       "  (0): SpectralRule(\n",
       "    (activation): Activation(sigmoid)\n",
       "  )\n",
       "  (1): SpectralRule(\n",
       "    (activation): Activation(sigmoid)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.]\n",
       " [33.]]\n",
       "<NDArray 2x1 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 0. ... 0. 0. 0.]\n",
       " [0. 1. 0. ... 0. 0. 0.]\n",
       " [0. 0. 1. ... 0. 0. 0.]\n",
       " ...\n",
       " [0. 0. 0. ... 1. 0. 0.]\n",
       " [0. 0. 0. ... 0. 1. 0.]\n",
       " [0. 0. 0. ... 0. 0. 1.]]\n",
       "<NDArray 34x34 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000 -- Loss:  1.4704\n",
      "[0.3539598, 0.35067835]\n",
      "Epoch 200/1000 -- Loss:  1.3379\n",
      "[0.57393706, 0.5428192]\n",
      "Epoch 300/1000 -- Loss:  1.1935\n",
      "[0.6062509, 0.49992096]\n",
      "Epoch 400/1000 -- Loss:  0.8140\n",
      "[0.56156254, 0.21099909]\n",
      "Epoch 500/1000 -- Loss:  0.3472\n",
      "[0.90632635, 0.2203265]\n",
      "Epoch 600/1000 -- Loss:  0.1100\n",
      "[0.95205736, 0.059061453]\n",
      "Epoch 700/1000 -- Loss:  0.0931\n",
      "[0.91495174, 0.0041596894]\n",
      "Epoch 800/1000 -- Loss:  0.0382\n",
      "[0.9647902, 0.002304521]\n",
      "Epoch 900/1000 -- Loss:  0.0114\n",
      "[0.99313897, 0.004508686]\n",
      "Epoch 1000/1000 -- Loss:  0.0121\n",
      "[0.998447, 0.010515097]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "feature_representations_1 = train(model_1, features_1, X_1, X_train, y_train, epochs=1000)\n",
    "y_pred_1 = predict(model_1, X_1, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.94      0.68        16\n",
      "         1.0       0.75      0.19      0.30        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.64      0.56      0.49        32\n",
      "weighted avg       0.64      0.56      0.49        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.asnumpy(), y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/250 -- Loss:  1.1695\n",
      "[0.5862159, 0.47027713]\n",
      "Epoch 50/250 -- Loss:  1.1351\n",
      "[0.53844905, 0.4031388]\n",
      "Epoch 75/250 -- Loss:  1.0982\n",
      "[0.51091605, 0.34729818]\n",
      "Epoch 100/250 -- Loss:  1.0190\n",
      "[0.54106814, 0.33290556]\n",
      "Epoch 125/250 -- Loss:  0.9039\n",
      "[0.6200222, 0.3468151]\n",
      "Epoch 150/250 -- Loss:  0.7781\n",
      "[0.7011682, 0.34495774]\n",
      "Epoch 175/250 -- Loss:  0.6298\n",
      "[0.75172514, 0.29135114]\n",
      "Epoch 200/250 -- Loss:  0.4786\n",
      "[0.777421, 0.20294072]\n",
      "Epoch 225/250 -- Loss:  0.3592\n",
      "[0.80039114, 0.12764798]\n",
      "Epoch 250/250 -- Loss:  0.2678\n",
      "[0.8348302, 0.083568335]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.94      0.71        16\n",
      "         1.0       0.83      0.31      0.45        16\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.71      0.62      0.58        32\n",
      "weighted avg       0.71      0.62      0.58        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_representations_2= train(model_2, features_2, X_2, X_train, y_train, epochs=250)\n",
    "y_pred_2 = predict(model_2, X_2, X_test)\n",
    "print(classification_report(y_test.asnumpy(), y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
