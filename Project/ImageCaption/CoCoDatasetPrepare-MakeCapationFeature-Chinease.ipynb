{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kent/git/aiacademy-learning-notebook/Project/ImageCaption/data/coco/annotations/instances_train2014.json\n",
      "-rw-rw-r-- 1 kent kent 318M Sep  1 18:56 /home/kent/git/aiacademy-learning-notebook/Project/ImageCaption/data/coco/annotations/instances_train2014.json\r\n"
     ]
    }
   ],
   "source": [
    "dataDir='/home/kent/git/aiacademy-learning-notebook/Project/ImageCaption/data/coco'\n",
    "dataType='train2014'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "\n",
    "print(annFile)\n",
    "!ls -alh $annFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.91s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO categories: \n",
      "person bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair drier toothbrush\n",
      "\n",
      "COCO supercategories: \n",
      "person electronic accessory animal food furniture sports indoor outdoor vehicle kitchen appliance\n"
     ]
    }
   ],
   "source": [
    "# display COCO categories and supercategories\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributor': 'COCO Consortium',\n",
       " 'date_created': '2017/09/01',\n",
       " 'description': 'COCO 2014 Dataset',\n",
       " 'url': 'http://cocodataset.org',\n",
       " 'version': '1.0',\n",
       " 'year': 2014}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.dataset['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['categories', 'licenses', 'annotations', 'images', 'info'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.99s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for caption annotations\n",
    "annFile = '{}/annotations/captions_{}.json'.format(dataDir,dataType)\n",
    "coco_caps=COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82783"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set =[]\n",
    "for img in coco.dataset['images']:\n",
    "#     print(img)\n",
    "#     print(img['file_name'])\n",
    "    \n",
    "    imgId = img['id']\n",
    "    \n",
    "    annIds = coco_caps.getAnnIds(imgIds=imgId)\n",
    "    anns = coco_caps.loadAnns(annIds)\n",
    "    \n",
    "    anns_list = []\n",
    "    for aann in anns:\n",
    "#         print(aann['caption'])\n",
    "        anns_list.append(aann['caption'])\n",
    "        \n",
    "    train_set.append((img['file_name'], anns_list))\n",
    "\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 進行翻譯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "\n",
    "credentials, project = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'做得好'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import translate\n",
    "\n",
    "\n",
    "translate_client = translate.Client(credentials=credentials)\n",
    "\n",
    "def translate(query):\n",
    "    target='zh_TW'\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(\n",
    "        query,\n",
    "        target_language=target)\n",
    "\n",
    "#     print(u'Text: {}'.format(result['input']))\n",
    "#     print(u'Translation: {}'.format(result['translatedText']))\n",
    "#     print(u'Detected source language: {}'.format(\n",
    "#         result['detectedSourceLanguage']))\n",
    "\n",
    "    return result['translatedText']\n",
    "translate(\"good job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "def doTranslate(x):\n",
    "    retry = 1\n",
    "    while True:\n",
    "        try:\n",
    "            fname,slist = x\n",
    "            smerge = \" @@ \".join(slist)\n",
    "        #     print(smerge)\n",
    "            translation = translate_client.translate(\n",
    "                smerge,\n",
    "                target_language= 'zh_tw')    \n",
    "            tslist = translation['translatedText'].split(\"@@\")\n",
    "            time.sleep(1)\n",
    "            return (fname,tslist)\n",
    "        except:\n",
    "            time.sleep(random.randint(20,30*retry))\n",
    "            slack_log(\"retry:{}\"%(retry))\n",
    "            print('*',end='')\n",
    "            retry += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slacker import Slacker\n",
    "import os\n",
    "slack = Slacker(os.environ['SLACK_TOKEN'])\n",
    "def slack_log(message):\n",
    "    try:\n",
    "        slack.chat.post_message('#log-traininglog', \"Translate {}\".format(message))\n",
    "    except:\n",
    "        print(\"slack connection error\")\n",
    "\n",
    "slack_log('Initial Logger')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=3)]: Done 1007 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=3)]: Done 1452 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=3)]: Done 1979 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=3)]: Done 2586 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=3)]: Done 3275 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=3)]: Done 4044 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=3)]: Done 4895 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=3)]: Done 5826 tasks      | elapsed: 35.7min\n",
      "[Parallel(n_jobs=3)]: Done 6839 tasks      | elapsed: 44.8min\n",
      "[Parallel(n_jobs=3)]: Done 7932 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=3)]: Done 9107 tasks      | elapsed: 65.1min\n",
      "[Parallel(n_jobs=3)]: Done 10362 tasks      | elapsed: 76.3min\n",
      "[Parallel(n_jobs=3)]: Done 11699 tasks      | elapsed: 88.2min\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from joblib import Parallel, delayed \n",
    "# List of arguments to pass to work():\n",
    "# Anything returned by work() can be stored:\n",
    "results = Parallel(n_jobs=3, verbose=2, backend=\"threading\")(map(delayed(doTranslate), train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(results,open(\"./data/coco/chinease_caption.pk\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('COCO_train2014_000000017153.jpg',\n",
       " ['沙灘上的一張毯子上放著兩個比薩餅，蔬菜和蘸醬，以及其他食物@ @野餐午餐和比薩餅和餃子坐在被子上。 ',\n",
       "  '兩個比薩餅坐在蔬菜旁邊，沾上甜點。 ',\n",
       "  '各種各樣的食物，包括毯子上的披薩和餃子。 ',\n",
       "  '一箱兩個比薩餅和一些某種包裝好的蔬菜。'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~\t\t\t\t\t\t       DoPrediction.ipynb\r\n",
      "BuildModel.ipynb\t\t\t\t       image_list.json\r\n",
      "caption_indexed.pk\t\t\t\t       MonitorGPU.ipynb\r\n",
      "CoCoDatasetPrepare-MakeCapationFeature-Chinease.ipynb  mytokenizer.pk\r\n",
      "CoCoDatasetPrepare-MakeCapationFeature.ipynb\t       OpenImage.ipynb\r\n",
      "CoCoDatasetPrepare-MakeImageFeature.ipynb\t       pycocoDemo.ipynb\r\n",
      "coco_model_ep_1.h5\t\t\t\t       SimpleTrial\r\n",
      "coco_model_ep_20.h5\t\t\t\t       tokenizer.pk\r\n",
      "coco_model_ep_7.h5\t\t\t\t       train.json\r\n",
      "coco_model_ep_9.h5\t\t\t\t       vgg16_feature.hdf5\r\n",
      "data\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model Download\n",
    "\n",
    "http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
